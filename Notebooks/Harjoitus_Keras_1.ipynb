{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Keras (ja TensorFlow) perusteet\n",
    "======================\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/TensorFlowLogo.svg/1229px-TensorFlowLogo.svg.png\" \n",
    "alt=\"TensorFlow\" width=\"400\"/>\n",
    "![Keras](https://upload.wikimedia.org/wikipedia/commons/c/c9/Keras_Logo.jpg \"Keras\")\n",
    "\n",
    "Asentaaksesi tarvittavat paketit omalla koneellasi harjoituksen suorittamista varten:\n",
    "```\n",
    "$ pip3 install scikit-learn pandas tensorflow numpy matplotlib==2.2.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "Nykyisellään TensorFlow suosittelee aloittelijoita lähtemään liikkeelle juuri [Keras](https://keras.io/)-API:n avulla. Keras sisältää kaksi hieman erityyppistä lähestymistapaa neuroverkkoihin: \n",
    "* [Sequential](https://keras.io/getting-started/sequential-model-guide/) on yksinkertaisempi, lineaarinen kasa neurotasoja. Tässä harjoituksessa keskitytään Sequential-API:in.\n",
    "* [Functional](https://keras.io/getting-started/functional-api-guide/) mahdollistaa monmimutkaisempien mallien rakentamisen, muun muassa mahdollistamalla useampia syöte- ja tulostetasoja\n",
    "\n",
    "Koska tässä harjoituksessa käytetään Kerasta TensoFlow:n kautta, Keras-dokumentaatiosta poiketen moduulien import-lauseet ovat hieman erilaiset. Esimerkiksi sen sijaan, että kirjoitettaisiin \n",
    "``` python\n",
    "from keras.layers import Dense\n",
    "layer = Dense(32, input_shape=(784,))\n",
    "```\n",
    "kirjoitetaankin\n",
    "``` python\n",
    "from tensorflow import keras\n",
    "layer = keras.layers.Dense(32, input_shape=(784,))\n",
    "```\n",
    "\n",
    "## Yksinkertainen neuroverkko\n",
    "Aluksi tehdään yksinkertainen luokittelu käyttäen hyväksi jo tutuksi tullutta [MNIST](https://en.wikipedia.org/wiki/MNIST_database)-aineistoa,joka sisältää käsinkirjoitettuja numeroita 0-9 kuvina. Lataa aineisto ja jaa se opetus- ja testijoukkoihin `X_train, X_test, y_train ja  y_test` siten, \n",
    "että testijoukon osuus on 20% ja opetusjoukon osuus on 80% havainnoista. Tällä kertaa käytä suoraan kuvia `dataset.images` äläkä yksiulotteisia havaintovektoreita `dataset.data`, sillä prosessointi tehdään myöhemmin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = None\n",
    "y = None\n",
    "\n",
    "X_train, X_test, y_train, y_test = None,None,None,None\n",
    "assert X and X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luo aluksi pelkkä [Sequential](https://keras.io/getting-started/sequential-model-guide/)-malli, johon \n",
    "myöhemmin lisätään tasoja `.add()`-metodilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "assert model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jotta mallin syötetaso ottaisi vastaan suoraan kaksiulotteisia kuvia, lisää malliin syötetaso, joka litistää havainnot yksiuloitteisiksi. Käytä tähän [Flatten](https://keras.io/layers/core/#flatten)-tasoa ja aseta sen `input_shape`-parametriksi pikseleiden koko. `input_shape`-parametria käytetään malleissa vain ensimmäisessä tasossa, jonka jälkeen malli osaa päätellä sen myöhemmissä tasoissa. Vinkki: saat yksittäisen kuvan koon selville `.shape`-metodilla.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lisää model-olioon taso\n",
    "model.add(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seuraavaksi lisää [Dense](https://keras.io/layers/core/#Dense)-taso, joka on yksinkertainen halutun kokoinen neuraalotaso. Aseta tason kooksi 100 ja lisää sille aktivointifunktioksi `\"relu\"` `activation`-parametrin avulla. Katso lisätietoja [dokumentaatiosta](https://keras.io/activations/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lisää model-olioon taso\n",
    "model.add(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ylisovituksen estämiseksi malleille voi olla hyvä lisätä [Dropout](https://keras.io/layers/core/#dropout)-taso. Tämä taso muuttaa satunnaisesti tietyn prosenttiosuuden painotuksista nollaksi opetusiteraatioiden aikana. Aseta pudotuksen asteeksi 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lisää model-olioon taso\n",
    "model.add(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mallille kerrottiin aluksi havaintojen koko `input_shape`-parametrilla ensimmäisessä tasossa. Samalla tavalla myös viimeisen tason haluttu koko on kerrottava mallille. Luokitteluongelmissa koko on tyypillisesti luokkien määrä. Painotukset halutaan kuitenkin muuttaa järkevästi tulkittaviksi, esimerkiksi todennäköisyysarvoiksi. Luokittelussa halutaan, että suurimman todennäköisyyden saanut luokka on luokittelutulos ja että kaikkien luokkien todennäköisyyslukemien summa olisi 1 jokaisella havainnolla. Tähän soveltuu mainiosti matemaattisesti [softmax](https://en.wikipedia.org/wiki/Softmax_function)-funktio.\n",
    "\n",
    "Lisää siis viimeiseksi tasoksi [Dense](https://keras.io/layers/core/#Dense)-taso, sen kooksi haluttu luokkien lukumäärä ja sen aktivointifunktioksi `\"softmax\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lisää model-olioon taso\n",
    "model.add(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malli on nyt valmis! Ennen opettamista malli täytyy vielä [koota](https://keras.io/models/sequential/#compile) (engl. compile) sopivan optimointifunktion ja häviöfunktion avulla. Käytetään tässä optimointifunktiona suosittua [`adam`](https://keras.io/optimizers/#adam)-funktiota.\n",
    "\n",
    "Luokitteluongelman häviöfunktioksi sopii tyypillisesti joko [categorical_crossentropy](https://keras.io/losses/#categorical_crossentropy) tai [sparse_categorical_crossentropy](https://keras.io/losses/#sparse_categorical_crossentropy) riippuen siitä, missä muodossa data luokat ovat. Tähän asti luokat ovat olleet vain yksittäisiä numeroita. One-hot -koodaustapaa käytettäessä luokka ilmoitetaan eri tavalla indeksin avulla. Esimerkiksi aiemmin käytetyllä tavalla luokkien joukko [0, 2, 1] esitettäisiin one-hot -koodaustavalla:`[1 0 0],  [0 0 1], [0 1 0]`. One-hot pyrkii siis hävittämään  One-hot -koodaustavan tapauksessa `\"categorical_crossentropy\"` olisi soveltuva häviöfunktio, `\"sparse_categorical_crossentropy\"` taas sopii perinteiseen tapaan. \n",
    "\n",
    "Häviön lisäksi malli myös laskee metriikoita opetuksen edetessä. Tyypillisesti `\"accuracy\"`-metriikka riittää. Se kuvaa yleistä tarkkuutta OA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kokoa model-olio\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opettaminen\n",
    "Mallin voi nyt opettaa. Tämä tehdään jo scikit-learn:ista tutulla `.fit()`-metodilla. Ylimääräiseksi parametriksi annetaan kuitenkin `epochs`, joka määrittää opetuksen keston koko opetusaineiston iteraatioina. Eli jos `epochs=10`, malli pääsee näkemään jokaisen opetusaineiston havainnon 10 kertaa opetuksen aikana. Liian suuri arvo voi johtaa ylisovitukseen ja liian pieni taas alisovitukseen. Valinnaisena parametrina voi antaa myös parametrin `batch_size`, eli erän koko. Erän koko kuva sitä kuinka kuinka monta havaintoa käsitellään kerrallaan. Siinä taas liian pieni arvo johtaa hitaaseen oppimiseen ja liian suuri taas voi johtaa alisovitukseen tai suorituskykyongelmiin.\n",
    "\n",
    "Mallin opettaminen tulostaa ruudulle jatkuvasti häviön ja tarkkuuden arvoa. Nämä kuvaavat siis kyseisen epookin sisällä opetusjoukon sisäistä häviötä ja tarkkuutta. Mitä pienempi häviö ja mitä suurempi tarkkuus, niin sitä parempi malli pitäisi olla. Kuitenkin näitä arvoja ei pidä sekoittaa testausaineistolla tehtävään evaluointiin ja vasta opetuksen jälkeinen evaluointi kertoo mallin kyvystä yleistyä ongelmaan.Jos näyttää siltä, ettei häviö pienene epookkien välillä, epookkeja saattaa olla liikaa.\n",
    "\n",
    "\n",
    "Opeta malli opetusjoukolla käyttäen 5 epookkia ja erän kokona 50 havaintoa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opeta model-olio\n",
    "history = model.fit(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opettaminen palauttaa `history`-olion, jota voi analysoida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist = hist.set_index('epoch')\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist[\"accuracy\"])\n",
    "plt.title('Mallin tarkkuus')\n",
    "plt.ylabel('OA')\n",
    "plt.xlabel('Epookki')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist[\"loss\"])\n",
    "plt.title('Mallin häviö')\n",
    "plt.ylabel('Häviö')\n",
    "plt.xlabel('Epookki')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testaaminen\n",
    "Mallin testaamiseksi voit käyttää `evaluate()`-metodia samaan tyyliin, kuin scikit-learn -luokittelijoissa `clf.score()`-funktiota.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluoi malli\n",
    "evaluation = None\n",
    "print(\"Testijoukon häviö: {:.4f} OA: {:.4f}\".format(evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voit myös käyttää scikit-learn -kirjaston evaluointitekniikoita. Muodosta aluksi `y_pred` aineisto mallin avulla käyttäen `.predict()`-metodia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = None\n",
    "print(\"Ensimmäinen alkio:\", y_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarkastelemalla `y_pred`-oliota huomaat, että yksittäinen alkio onkin luokan sijasta lista todennäköisyyksiä<sup>1</sup>. \n",
    "Ensimmäinen luku on luokan 0 todennäköisyys, toinen luku luokan 1 todennäköisyys ja niin edelleen. Luokitellun luokan saamiseksi on siis otettava suurimman todennäköisyyden saaneen indeksi. \n",
    "Tähän voi käyttää [`np.argmax()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html)-metodia.\n",
    "\n",
    "\n",
    "<sup>1</sup>Myös Scikit-learn-kirjastosta on mahdollista saada todennäköisyysarvot luokkien lisäksi. Joidenkin\n",
    " algoritmien, kuten SVM:n tapauksessa tällöin on annettava parametri `probability=True` mallia luotaessa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred_probs = y_pred\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "print(\"Suurimman todennäköisyyden saanut luokka: {}, sen saama todennäköisyys: {:.4f}\".format(\n",
    "    y_pred[0], y_pred_probs[0][y_pred[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muodosta luokitteluraportti ja sekaannusmatriisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from utils import plot_confusion_matrix\n",
    "\n",
    "report = None\n",
    "cm = None\n",
    "plot_confusion_matrix(cm, list(range(10)), list(range(10)), normalize=True)\n",
    "\n",
    "assert report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mallin muokkaaminen\n",
    "Kokeile seuraavaksi muokata mallia paremmaksi. Kopioi malli osa osalta alle `build_fn()`-funktion sisälle, jotta voit muuttaa parametreja helpommin. Käytä funktion parametreja ja voit lisätä omia parametreja muokkaamisen helpottamiseksi, mutta muist antaa niille oletusarvo. Voit lisätä malliin uusia (Dense-) tasoja ja voit muuttaa niiden kokoa ja poiston määrää. Muuta myös erien kokoa ja epookkien määriä. Älä kuitenkaan käytä liian isoja epookkilukuja (>20) tai neuronitasojen kokoja (>10000), jottei mallin opettaminen hidastu liikaa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_fn(param1=None, param2=None):\n",
    "    # Kopioi malli yllä olevista soluista sisältäen koontivaiheen (model.compile())\n",
    "    model = None\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model\n",
    "    \n",
    "# Muokkaa parametrejä\n",
    "model = build_fn(param1=None, param2=None)\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=50)\n",
    "evaluation = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testijoukon häviö: {:.4f} OA: {:.4f}\".format(evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mallin tallentaminen\n",
    "Kuten Scikit-learn:in tapauksessa, myös Keras-malleja voi tallentaa levylle. \n",
    "Neuroverkkojen opettaminen on usein hidasta puuhaa, mutta onneksi myös välituloksia opetuksessa \n",
    "voi tallentaa ja opetusta voi tarvittaessa jatkaa edellisestä kohdasta tallentamalla mallin painot.  \n",
    "\n",
    "[Dokumentaation](https://keras.io/callbacks/#modelcheckpoint) perusteella luo `keras.callbacks.ModelCheckpoint`-funktio, joka tallentaa vain parhaat painot tiedostoon \"keras-mnist-model-best-weights.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_location = \"keras-mnist-model-best-weights.ckpt\"\n",
    "\n",
    "cp_callback = None\n",
    "assert cp_callback\n",
    "\n",
    "model = build_fn()\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=50, callbacks = [cp_callback])\n",
    "evaluation = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testijoukon häviö: {:.4f} OA: {:.4f}\".format(evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluoi tyhjää mallia\n",
    "model = build_fn()\n",
    "evaluation = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Painottoman mallin Testijoukon häviö: {:.4f} OA: {:.4f}\".format(evaluation[0], evaluation[1]))\n",
    "\n",
    "# Evaluoi mallia painojen lataamisen jälkeen\n",
    "model.load_weights(checkpoint_location)\n",
    "evaluation = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Painnollisen mallin Testijoukon häviö: {:.4f} OA: {:.4f}\".format(evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lue halutessasi lisää mallin tallentamisesta [täältä](https://www.tensorflow.org/tutorials/keras/save_and_restore_models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn yhteensopivuus\n",
    "Äskeinen hyperparametrien optimointi saattoi tuntua aika manuaaliselta edellisten harjoitusten \n",
    "automatisoitujen keinojen jälkeen. Pystyisiköhän samoja menetelmiä käyttämään myös Keras-mallien kanssa? \n",
    "Kyllä [pystyy](https://keras.io/scikit-learn-api/)! Samoin Keras-mallin voi ottaa käyttöön\n",
    " laajemmassa Scikit-learn ympäristössä  ja siihen voi jopa soveltaa \n",
    " [putkitusta](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), \n",
    " mikä tuo paljon hyötyjä esimerkiksi datan esikäsittelyn (esim. standardtointi, pca) osalta.\n",
    "\n",
    "Luo ensin `clf`-olio [dokumentaation](https://keras.io/scikit-learn-api/) \n",
    "avulla antamatta mitään muita parametreja, kuin `build_fn`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "clf = None\n",
    "assert clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luo sitten parametriverkko ja [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    ". Luomasi `build_fn` parametrien lisäksi voit antaa parametreina myös opettamiseen tarvittavia parametreja, kuten `\"epochs\"` ja `\"batch_size\"`. Muista, että GridSearchCV käyttää ristivalidointia (CV=3 oletuksena), eli liian paljon eri aikaavieviä parametrikokeiluja ei kannata tehdä kerralla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = None\n",
    "clf = GridSearchCV(clf, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Parhaat parametrit: \", clf.best_params_)\n",
    "print(\"Paras opetus OA: {:.4f}\".format(clf.best_score_))\n",
    "print(\"OA: {:.4f}\".format(clf.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lisenssi\n",
    "Osa tämän harjoituksen esimerkeistä on muokattu sivun https://www.tensorflow.org/tutorials esimerkeistä.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title MIT License\n",
    "#\n",
    "# Copyright (c) 2017 François Chollet\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the \"Software\"),\n",
    "# to deal in the Software without restriction, including without limitation\n",
    "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "# and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    "# DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
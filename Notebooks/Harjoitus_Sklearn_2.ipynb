{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Scikit-learn harjoitus 2\n",
    "======================\n",
    "\n",
    "Tämän harjoituksen tarkoitus on opettaa hieman edistyksellisimpiä toimintoja.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressio\n",
    "Regressio-ongelma:\n",
    "\n",
    "TODO: selitys\n",
    "\n",
    "Kokeile ainakin [näistä](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datan koko:  20640\n",
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = datasets.fetch_california_housing()\n",
    "X = data.data\n",
    "y = data.target\n",
    "print(\"Datan koko: \", len(y))\n",
    "print(data.DESCR)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # TODO: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 1.48196324e-01  5.72821070e-03  0.00000000e+00 -0.00000000e+00\n",
      " -8.16437293e-06 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00]\n",
      "Mean squared error: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "regr = Lasso()#SGDRegressor()# LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "print(\"Mean squared error: {:.2f}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kuvien käyttäminen datana\n",
    "Aloita lataamalla harjoitusdata. Tällä kertaa käytetään [MNIST](https://en.wikipedia.org/wiki/MNIST_database)-aineistoa,\n",
    "joka sisältää käsinkirjoitettuja numeroita 0-9 8x8 pikselin kuvina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esimerkkikuva pikseliarvoina: \n",
      " [[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "Esimerkkikuva havaintovektorina: \n",
      " [ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "dataset = datasets.load_digits()\n",
    "\n",
    "# Näytetään ensimmäinen kuva\n",
    "plt.imshow(dataset.images[0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.title('Esimerkkikuva')\n",
    "plt.show()\n",
    "\n",
    "print(\"Esimerkkikuva pikseliarvoina: \\n\", dataset.images[0])\n",
    "\n",
    "# dataset-olio tarjoaa havainnot myös valmiiksi prosessoituna yhdeksi vektoriksi/listaksi\n",
    "print(\"Esimerkkikuva havaintovektorina: \\n\", dataset.data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jotta kuvista, eli n*m-taulukoista päästään yksiulotteiseen havaintovektorimuotoon, ne pitää prosessoida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kuvat ovat nyt yksiulotteisia\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(dataset.images)\n",
    "data = dataset.images.reshape((n_samples, -1))\n",
    "if np.array_equal(data, dataset.data):\n",
    "    print(\"Kuvat ovat nyt yksiulotteisia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Nyt edellistä harjoitusta hyväksi käyttäen suorita vaiheet ja luokittele malli haluamallasi algoritmilla \n",
    "ja parametreilla. Yritä päästä yleiseen tarkkuuteen OA>=0.9.\n",
    "\n",
    "Jaa luomasi X ja luokat y opetus- ja testijoukkoihin `X_train, X_test, y_train ja  y_test` siten, \n",
    "että testijoukon osuus on 20% ja opetusjoukon osuus on 80% havainnoista. \n",
    "Käytä jaossa `random_state`-parametrin arvona 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data\n",
    "y = dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # TODO: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Opeta malli ja luo ennustukset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluoi\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utils import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Epätasapainon korjaaminen\n",
    "Jos luokkien määrä havaintojen välillä on epätasapainossa, malli suosii helposti luokkia, joissa on enemmän havaintoja, kuin toisissa. Tämä on yksi koneoppimisen suurista ongelmista. Yksi keino hallita ongelmaa, on havaintojen resamplaus, eli havaintojen määrän muuttaminen opetusjoukossa siten, että luokkien välinen epätasapaino pienenisi.\n",
    "\n",
    "Tähän on kaksi menetelmää: \n",
    "* Havaintojen lisääminen pienimpiin luokkiin\n",
    "* Havaintojen poistaminen suurimmista luokista\n",
    "\n",
    "\n",
    "TODO: lisää tekstiä!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 145, 1: 154, 2: 144, 3: 149, 4: 135, 5: 135, 6: 146, 7: 145, 8: 144, 9: 140}\n",
      "OrderedDict([(0, 50), (1, 154), (2, 144), (3, 70), (4, 135), (5, 135), (6, 80), (7, 145), (8, 144), (9, 60)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joona/IdeaProjects/MLCourse/venv/forNb/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alkuperäinen OA: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joona/IdeaProjects/MLCourse/venv/forNb/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epätasapainoisen OA: 0.31\n"
     ]
    }
   ],
   "source": [
    "from imblearn.datasets import make_imbalance\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "sampling_strategy = {0: 50, 1: 154, 2: 144, 3: 70, 4: 135, 5: 135, 6: 80, 7: 145, 8: 144, 9: 60}\n",
    "X_train2, y_train2 =  make_imbalance(X_train, y_train, sampling_strategy=sampling_strategy)\n",
    "\n",
    "print(dict(OrderedDict(sorted(Counter(y_train).items(), key=lambda t: t[0]))))\n",
    "print(dict(OrderedDict(sorted(Counter(y_train2).items(), key=lambda t: t[0]))))\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Alkuperäinen OA: {:.2f}\".format(clf.score(X_test, y_test)))\n",
    "\n",
    "clf.fit(X_train2, y_train2)\n",
    "print(\"Epätasapainoisen OA: {:.2f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 154, 1: 154, 2: 154, 3: 154, 4: 154, 5: 154, 6: 154, 7: 154, 8: 154, 9: 154}\n",
      "{0: 50, 1: 50, 2: 50, 3: 50, 4: 50, 5: 50, 6: 50, 7: 50, 8: 50, 9: 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joona/IdeaProjects/MLCourse/venv/forNb/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alkuperäinen OA: 0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joona/IdeaProjects/MLCourse/venv/forNb/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epätasapainoisen OA: 0.54\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_train_oversampled, y_train_oversampled = ros.fit_resample(X_train2, y_train2)\n",
    "rus = RandomUnderSampler()\n",
    "X_train_undersampled, y_train_underrsampled = rus.fit_resample(X_train2, y_train2)\n",
    "\n",
    "print(dict(OrderedDict(sorted(Counter(y_train_oversampled).items(), key=lambda t: t[0]))))\n",
    "print(dict(OrderedDict(sorted(Counter(y_train_underrsampled).items(), key=lambda t: t[0]))))\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train_oversampled, y_train_oversampled)\n",
    "print(\"Oversampled OA: {:.2f}\".format(clf.score(X_test, y_test)))\n",
    "\n",
    "clf.fit(X_train_undersampled, y_train_underrsampled)\n",
    "print(\"Undersampled OA: {:.2f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ristivalidointi\n",
    "Myös testijoukon ylisovitus on mahdollista kun mallia säädetään paljon. Tällöin on mahdollista käyttää kolmatta validointijoukkoa, mutta ristivalidointi on toinen (ja monesti parempi) vaihtoehto. Siinä käytetään hyväksi vain opetusjoukkoa, joka jaetaan osiin siten, että vuorollaan jokainen havainto on ristivalidoinnin sisäisessä opetusjoukossa ja vuorollaan testijoukossa. Näitä kutsutaan jaoiksi (engl. split). Tällöin oikeaa testijoukkoa voi säästää aivan viimeiseen säädetyn mallin validointiin saakka.\n",
    "\n",
    "Suorita alla yksinkertainen ristivalidointi käyttäen [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)-metodia ja haluamaasi luokittelualgoritmia. Aseta `CV`-parametri arvoksi 5 ja `n_jobs`-parametri arvoon -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pisteet ovat:\n",
      "    OA: 0.74\n",
      "    OA: 0.75\n",
      "    OA: 0.76\n",
      "    OA: 0.76\n",
      "    OA: 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma=0.01)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, n_jobs=-1)\n",
    "print(\"Pisteet ovat:\")\n",
    "for oa in scores:\n",
    "    print(\"    OA: {:.2f}\".format(oa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`n_jobs`-parametri mahdollisti rinnakkaisen laskennan eri mallien välille. Tämä parametri löytyy jokaisesta ristivalidointia käyttävästä metodista ja myös joistain luokittelijoista, kuten Random Forest. Sitä suositellaan käytettäväksi aina kun on mahdollista, mutta harjoituksissa sen käyttöä on vältetty suorituskyvyn vuoksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Putkittaminen\n",
    "Ristivalidoinnissa datan esikäsittely, joka riippuu datasta, on hyvä suorittaa erikseen jokaiselle jaolle. Tämä on helpoin tehdä käyttämällä putkitusta ([pipelines](https://scikit-learn.org/stable/modules/compose.html#pipeline)). Sillä tavoin on mahdollista kytkeä paljon esikäsittelyvaiheita yhteen ja suorittaa vaiheet jokaisen jaon kohdalla. Putkitusta on syytä käyttää myös hyperparametrioptimoinnin kanssa.\n",
    "\n",
    "Suorita ensin äskeinen ristivalidointi uudestaan käyttäen moduulia [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) vaiheita [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) ja [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html), sekä haluaamasi luokittelualgoritmia. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pisteet ovat:\n",
      "    OA: 0.97\n",
      "    OA: 0.97\n",
      "    OA: 0.97\n",
      "    OA: 0.99\n",
      "    OA: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe = Pipeline([(\"standard_scaler\", StandardScaler()), (\"pca\", PCA()), (\"clf\", SVC(gamma=0.01))])\n",
    "scores = cross_val_score(pipe, X_train, y_train, cv=5, n_jobs=-1)\n",
    "print(\"Pisteet ovat:\")\n",
    "for oa in scores:\n",
    "    print(\"    OA: {:.2f}\".format(oa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suorita sama uudestaan käyttäen helppokäyttöisempää metodia [make_pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pisteet ovat:\n",
      "    OA: 0.97\n",
      "    OA: 0.97\n",
      "    OA: 0.97\n",
      "    OA: 0.99\n",
      "    OA: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(StandardScaler(), PCA(), SVC(gamma=0.01))\n",
    "scores = cross_val_score(pipe, X_train, y_train, cv=5, n_jobs=-1)\n",
    "print(\"Pisteet ovat:\")\n",
    "for oa in scores:\n",
    "    print(\"    OA: {:.2f}\".format(oa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lue halutessasi lisää ristivalidoinnista [täältä](https://scikit-learn.org/stable/modules/cross_validation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
